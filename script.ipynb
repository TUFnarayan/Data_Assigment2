{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVgyJTvX9Q6K"
      },
      "outputs": [],
      "source": [
        "pip install requests pandas boto3 snowflake-connector-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0NjV4Dm9Stv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def extract_data():\n",
        "    url = \"https://fakestoreapi.com/products\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    df = pd.json_normalize(data)\n",
        "\n",
        "\n",
        "    df.to_csv(\"products.csv\", index=False)\n",
        "    print(\"✅ Data extracted and saved as products.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiZnCRta9UMr"
      },
      "outputs": [],
      "source": [
        "\n",
        "import boto3\n",
        "import os\n",
        "from botocore.exceptions import NoCredentialsError, ClientError\n",
        " \n",
        "\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = 'asdasdas'\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = 'testestets'\n",
        " \n",
        "def upload_to_s3(file_name, bucket_name, object_name=None):\n",
        "    try:\n",
        "        s3 = boto3.client('s3')\n",
        " \n",
        "        if object_name is None:\n",
        "            object_name = file_name\n",
        " \n",
        "      \n",
        "        try:\n",
        "            s3.head_bucket(Bucket=bucket_name)\n",
        "        except ClientError as e:\n",
        "            print(f\"❌ Bucket '{bucket_name}' not found or inaccessible: {e}\")\n",
        "            return\n",
        " \n",
        "  \n",
        "        s3.upload_file(file_name, bucket_name, object_name)\n",
        "        print(f\"✅ '{file_name}' uploaded to S3 bucket '{bucket_name}' as '{object_name}'\")\n",
        " \n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ File '{file_name}' not found.\")\n",
        "    except NoCredentialsError:\n",
        "        print(\"❌ AWS credentials not found. Check your environment variables.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Upload failed: {e}\")\n",
        " \n",
        "if __name__ == \"__main__\":\n",
        "    upload_to_s3(\"products.csv\", \"tuf-narayan-data-bucket\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eHrOyk09VcV"
      },
      "outputs": [],
      "source": [
        "\n",
        "import snowflake.connector\n",
        "import pandas as pd\n",
        "\n",
        "def load_to_snowflake():\n",
        "    df = pd.read_csv(\"products.csv\")\n",
        "\n",
        "\n",
        "    expected_cols = ['id', 'title', 'price', 'description', 'category', 'image']\n",
        "    missing = [col for col in expected_cols if col not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing expected columns in CSV: {missing}\")\n",
        "\n",
        "    conn = snowflake.connector.connect(\n",
        "        user='TUFNARAYAN',\n",
        "        password='testesttest',\n",
        "        account='testtest'\n",
        "    )\n",
        "    cur = conn.cursor()\n",
        "\n",
        "\n",
        "    cur.execute(\"CREATE DATABASE IF NOT EXISTS DATA_PIPELINE_DB;\")\n",
        "    cur.execute(\"USE DATABASE DATA_PIPELINE_DB;\")\n",
        "    cur.execute(\"CREATE SCHEMA IF NOT EXISTS RAW_SCHEMA;\")\n",
        "\n",
        "    \n",
        "    cur.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE RAW_SCHEMA.PRODUCTS_RAW (\n",
        "        id INT,\n",
        "        title STRING,\n",
        "        price FLOAT,\n",
        "        description STRING,\n",
        "        category STRING,\n",
        "        image STRING\n",
        "    );\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        cur.execute(\"\"\"\n",
        "            INSERT INTO RAW_SCHEMA.PRODUCTS_RAW (id, title, price, description, category, image)\n",
        "            VALUES (%s, %s, %s, %s, %s, %s)\n",
        "        \"\"\", (int(row['id']), row['title'], float(row['price']), row['description'], row['category'], row['image']))\n",
        "\n",
        "    print(\"✅ Raw data loaded into Snowflake\")\n",
        "\n",
        "   \n",
        "    cur.execute(\"\"\"\n",
        "    CREATE OR REPLACE VIEW RAW_SCHEMA.PRODUCTS_TRANSFORMED AS\n",
        "    SELECT\n",
        "        category,\n",
        "        COUNT(*) AS product_count,\n",
        "        AVG(price) AS avg_price\n",
        "    FROM RAW_SCHEMA.PRODUCTS_RAW\n",
        "    GROUP BY category;\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"✅ Created transformed view in Snowflake\")\n",
        "\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    load_to_snowflake()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
